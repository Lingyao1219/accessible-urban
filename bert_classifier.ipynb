{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c4cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4573c59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingyaoli/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, TrainerCallback\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57898618",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('train.jsonl', lines=True)\n",
    "test_df = pd.read_json('test.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19b3ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do not stay here. They will rob you upon moveo...</td>\n",
       "      <td>They will rob you blind and send you the bill.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love the place. Im disabled so Im always dropp...</td>\n",
       "      <td>Im disabled so Im always dropping batteries an...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very friendly staff.  Verg accommidating.  Cha...</td>\n",
       "      <td>Changed our room to handicappedat the last min.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Truly one stop shopping. The could use some mo...</td>\n",
       "      <td>The could use some more handicapped carts, and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was a very clean and accessible establishment</td>\n",
       "      <td>It was a very clean and accessible establishment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Do not stay here. They will rob you upon moveo...   \n",
       "1  Love the place. Im disabled so Im always dropp...   \n",
       "2  Very friendly staff.  Verg accommidating.  Cha...   \n",
       "3  Truly one stop shopping. The could use some mo...   \n",
       "4   It was a very clean and accessible establishment   \n",
       "\n",
       "                                         target_text  annotation  \n",
       "0     They will rob you blind and send you the bill.           3  \n",
       "1  Im disabled so Im always dropping batteries an...           3  \n",
       "2    Changed our room to handicappedat the last min.           1  \n",
       "3  The could use some more handicapped carts, and...           0  \n",
       "4   It was a very clean and accessible establishment           3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_map = {\n",
    "    'positive': 2, \n",
    "    'negative': 0, \n",
    "    'neutral': 1, \n",
    "    'unrelated': 3\n",
    "    }\n",
    "\n",
    "train_df['annotation'] = train_df['annotation'].str.lower()\n",
    "test_df['annotation'] = test_df['annotation'].str.lower()\n",
    "\n",
    "train_df['annotation'] = train_df['annotation'].map(value_map)\n",
    "test_df['annotation'] = test_df['annotation'].map(value_map)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a7ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['negative', 'neutral', 'positive', 'unrelated']\n",
    "\n",
    "X_train = train_df['target_text']\n",
    "y_train = train_df['annotation']\n",
    "\n",
    "X_test = test_df['target_text']\n",
    "y_test = test_df['annotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da29ef",
   "metadata": {},
   "source": [
    "### Model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d6e88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingyaoli/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Check gpu availability\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def data_processing(df):\n",
    "    \"\"\"Process the data for training and testing based on bert tokenizer\"\"\"\n",
    "    sequences = df['target_text'].tolist()\n",
    "    labels = df['annotation'].tolist()\n",
    "    encodings = tokenizer(sequences, truncation=True, padding=True)\n",
    "\n",
    "    class TextDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}  # Move tensors to the selected device\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long).to(device)  # Ensure labels are on the correct device\n",
    "            return item\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    return TextDataset(encodings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "649d9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"Compute the metrics for the model\"\"\"\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd649af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# adjust the number based on classification labels\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4).to(device)\n",
    "\n",
    "global_best_model = None\n",
    "global_best_f1 = 0\n",
    "\n",
    "def training_objective(trial):\n",
    "    \"\"\"Define the training process using the bert model\"\"\"\n",
    "    global global_best_model\n",
    "    global global_best_f1\n",
    "    \n",
    "    # Define the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          \n",
    "        num_train_epochs=trial.suggest_int(\"num_train_epochs\",1,5), \n",
    "        per_device_train_batch_size=trial.suggest_categorical(\"per_device_train_batch_size\", [16,32,64]),  \n",
    "        per_device_eval_batch_size=64,  \n",
    "        warmup_steps=500,                \n",
    "        weight_decay=0.01,               \n",
    "        logging_dir='./logs',  \n",
    "    )\n",
    "    \n",
    "    total_f1 = 0\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_df)):\n",
    "        train_fold = data_processing(train_df.iloc[train_index])\n",
    "        val_fold = data_processing(train_df.iloc[val_index])\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model.to(device),\n",
    "            args=training_args,\n",
    "            train_dataset=train_fold,\n",
    "            eval_dataset=val_fold,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.train()\n",
    "\n",
    "        # Evaluate the model\n",
    "        eval_result = trainer.evaluate()\n",
    "        total_f1 += eval_result['eval_f1']\n",
    "\n",
    "    mean_f1 = total_f1 / kf.get_n_splits()\n",
    "    if mean_f1 > global_best_f1:\n",
    "        global_best_f1 = mean_f1\n",
    "        global_best_model = model\n",
    "        # Uncomment the following line to save the best model\n",
    "        # global_best_model = trainer.save_model(\"best_model\") \n",
    "    trial.set_user_attr('mean_f1', mean_f1)\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f1fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(training_objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168447a5",
   "metadata": {},
   "source": [
    "### Report model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0542f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the saved best model\n",
    "best_model = BertForSequenceClassification.from_pretrained(\"./best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64dc1033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e5a7480bc24cb8954e701ae0240eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/284 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76d752baf3a43bd8ea4159a8b65f60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 80.99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.81      0.74       127\n",
      "     neutral       0.44      0.35      0.39        23\n",
      "    positive       0.88      0.78      0.82       129\n",
      "   unrelated       0.88      0.86      0.87       289\n",
      "\n",
      "    accuracy                           0.81       568\n",
      "   macro avg       0.72      0.70      0.71       568\n",
      "weighted avg       0.81      0.81      0.81       568\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_processing(train_df)\n",
    "test_dataset = data_processing(test_df)\n",
    "\n",
    "# Define a new trainer with the best model\n",
    "best_trainer = Trainer(model=best_model)\n",
    "\n",
    "# Get predictions on training set\n",
    "train_predictions = best_trainer.predict(train_dataset)\n",
    "train_preds = np.argmax(train_predictions.predictions, axis=1)\n",
    "acc_train = accuracy_score(y_train, train_preds)  # Ensure this accesses the correct labels\n",
    "\n",
    "print(f\"train accuracy: {acc_train*100:.2f}%\")\n",
    "\n",
    "# Get predictions on testing set\n",
    "test_predictions = best_trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
    "acc_test = accuracy_score(y_test, test_preds)  # Ensure this accesses the correct labels\n",
    "print(f\"test accuracy: {acc_test*100:.2f}%\")\n",
    "\n",
    "print(classification_report(y_test, test_preds, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4afe19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   5   2  17]\n",
      " [ 11   8   0   4]\n",
      " [ 15   0 100  14]\n",
      " [ 23   5  12 249]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfcb6d",
   "metadata": {},
   "source": [
    "### Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd33845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from process_text import *\n",
    "\n",
    "mapping = {0: 'negative', 1: 'neutral', 2: 'positive', 3: 'unrelated'} \n",
    "\n",
    "def classify_text(df):\n",
    "    \"\"\"Classify the text based on the trained bert model\"\"\"\n",
    "    df['targeted_text'] = df['text'].apply(process_comment)\n",
    "    df = df.dropna(subset=['targeted_text'])\n",
    "    df = df[df['targeted_text'] != '']\n",
    "    sequences = df['parking_text'].astype(str).tolist()\n",
    "    tokenized_sequences = tokenizer(sequences, truncation=True, padding=True)\n",
    "    new_dataset = InferenceDataset(tokenized_sequences)\n",
    "    predictions = best_trainer.predict(new_dataset)\n",
    "    predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "    df['predicted_labels'] = predicted_labels\n",
    "    df['predicted_labels'] = df['predicted_labels'].replace(mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3768a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the trained model to classify the comment for each file\n",
    "\n",
    "save_folder = 'accessible-review-classification'\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "read_folder = 'accessible-review'\n",
    "read_files = [file for file in os.listdir(read_folder) if file.endswith('.csv')]\n",
    "read_files = sorted(read_files)\n",
    "print(read_files)\n",
    "    \n",
    "for read_file in read_files:\n",
    "    save_file = read_file.split('.csv')[0] + \"_classification.csv\"\n",
    "    read_filepath = os.path.join(read_folder, read_file)\n",
    "    print(f'----- process {read_filepath}')\n",
    "    save_filepath = os.path.join(save_folder, save_file)\n",
    "    reader = pd.read_csv(read_filepath, chunksize=1000)\n",
    "    chunks = []\n",
    "    for chunk in reader:\n",
    "        chunk = classify_text(chunk)\n",
    "        chunks.append(chunk)\n",
    "    df = pd.concat(chunks)\n",
    "    df.to_csv(save_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6baa16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
